{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Score Iris categorization algorithm\n",
    "\n",
    "## Context\n",
    "\n",
    "Working through using training/test splitting of the dataset to evluate the simple k-nearest neighbors predictive algorithm code I wrote earlier.\n",
    "\n",
    "## Work outline\n",
    "\n",
    "I am following the tutorial found at [this_site](https://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/) and walking through a simple example of predicting iris species using the well known [iris_petal_dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data).\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. import module from local filepath; load local data file\n",
    "2. split the dataset into training and test populations\n",
    "3. run predict_category_from_knn on test set to generate predictions\n",
    "4. find score for algorithm\n",
    "5. scale datasets by both range normalization and standardization\n",
    "6. run algorithm with scaled features and score new predictions\n",
    "\n",
    "\n",
    "## Result\n",
    "\n",
    "The feature-scaled versions of the algorithm scored worse than the raw knn. This is interesting. Makes me more interested in optimizing a model on scaled features with distance weights per feature. This will be crucial for having a working knn regression for price prediction.\n",
    "\n",
    "## Next steps\n",
    "\n",
    "Next will incorporate a feature weighting parameter. As part of this workflow will need to divide 90 : 30 : 30, training : validation : test datasets to use to optimize feature weights.\n",
    "\n",
    "Will also take \"on the fly\" functions defined in this workflow and incorporate them into the module.\n",
    "\n",
    "Later will build on \"scratch implementation\" to extend to predicting a continuous variable output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. import module from local filepath; load local data file\n",
    "\n",
    "Also cleanup the dataset to prepare for applying functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from knn_base import euclidean_distance\n",
    "from knn_base import find_k_neighbors\n",
    "from knn_base import predict_category_from_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw dataset\n",
    "with open('data/iris_data.csv', 'r') as f:\n",
    "    lines = csv.reader(f)\n",
    "    dataset = list(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the category variable to integer to enable numpy array loading\n",
    "iris_species_key = {\n",
    "    'Iris-setosa': 0,\n",
    "    'Iris-versicolor': 1,\n",
    "    'Iris-virginica': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataset = []\n",
    "for row in dataset:\n",
    "    new_row = []\n",
    "    for i in range(len(row)):\n",
    "        if i < 4:\n",
    "            new_row.append(float(row[i]))\n",
    "        else:\n",
    "            new_row.append(iris_species_key[row[i]])\n",
    "    cleaned_dataset.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.1, 3.5, 1.4, 0.2, 0],\n",
       " [4.9, 3.0, 1.4, 0.2, 0],\n",
       " [4.7, 3.2, 1.3, 0.2, 0],\n",
       " [4.6, 3.1, 1.5, 0.2, 0],\n",
       " [5.0, 3.6, 1.4, 0.2, 0]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = np.array(cleaned_dataset, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. split the dataset into training and test populations\n",
    "\n",
    "using element indices of the numpy array to simplify randomly splitting the dataset to training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(4).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(2).ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((np.ones(4), np.zeros(2)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a 1/3 : 2/3 split I'm using a shuffled list\n",
    "# of 100 ones and 50 zeros\n",
    "split_array = np.concatenate((np.ones(100), np.zeros(50)), 0)\n",
    "np.random.shuffle(split_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 50, 1.0: 100})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(split_array[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 30, 1.0: 70})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(split_array[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 7, 1.0: 23})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(split_array[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 3, 4]),)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(split_array[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_indices = np.where(split_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_array = dataset_array[split_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_array[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = np.where(split_array == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_array = dataset_array[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_array[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. run predict_category_from_knn on test set to generate predictions\n",
    "\n",
    "Run `predict_category_from_knn` for each row in the test set in a loop. Take the list of predictions and compare to the actual identified species key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 4]]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category_from_knn(test_set_array[0], training_set_array, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_predictions = []\n",
    "for row in test_set_array:\n",
    "    predictions = predict_category_from_knn(row, training_set_array, 4, 4)\n",
    "    prediction = predictions[0][0]\n",
    "    test_set_predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_predictions[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. find score for algorithm\n",
    "\n",
    "Use an element-wise comparison between the prediction and actual arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/siddiqui/Projects/venvs/knn_tutorial/lib/python2.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# this is the wrong way to do it\n",
    "accuracy_array = np.array(test_set_predictions) == training_set_array[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3, 4]) == np.array([1, 2, 0, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'bool' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-72cb12c84dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "accuracy_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_array = np.equal(test_set_predictions, test_set_array[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 4, True: 46})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(accuracy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = float(Counter(accuracy_array)[True])/len(test_set_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. scale features in dataset\n",
    "\n",
    "First will re-scale the features to make modified datasets. Will try both normalized and standardized feature scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.9\n",
      "4.3\n",
      "5.843333333333334\n",
      "0.8253012917851409\n"
     ]
    }
   ],
   "source": [
    "print dataset_array[:, 0].max()\n",
    "print dataset_array[:, 0].min()\n",
    "print dataset_array[:, 0].mean()\n",
    "print dataset_array[:, 0].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9., 23., 14., 27., 16., 26., 18.,  6.,  5.,  6.]),\n",
       " array([4.3 , 4.66, 5.02, 5.38, 5.74, 6.1 , 6.46, 6.82, 7.18, 7.54, 7.9 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataset_array[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_less_min = dataset_array[:, :4] - dataset_array[:, :4].min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.3, 2. , 1. , 0.1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:, :4].min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 1.5, 0.4, 0.1],\n",
       "       [0.6, 1. , 0.4, 0.1],\n",
       "       [0.4, 1.2, 0.3, 0.1],\n",
       "       [0.3, 1.1, 0.5, 0.1],\n",
       "       [0.7, 1.6, 0.4, 0.1]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_less_min[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.9, 4.4, 6.9, 2.5])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:, :4].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.6, 2.4, 5.9, 2.4])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:, :4].max(axis=0) - dataset_array[:, :4].min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_range = dataset_array[:, :4].max(axis=0) - dataset_array[:, :4].min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_dataset = features_less_min / norm_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9., 23., 14., 27., 22., 20., 18.,  6.,  5.,  6.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normed_dataset[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[4:].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normed_dataset.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 5)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[4:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_array[:, 4:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667, 0.        ],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667, 0.        ],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667, 0.        ],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667, 0.        ],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667, 0.        ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((normed_dataset, dataset_array[:, 4:]), axis=1)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_dataset(dataset, vector_length):\n",
    "    \"\"\"normalize features in dataset\n",
    "    \"\"\"\n",
    "    norm_range = dataset[:, :vector_length].max(axis=0) - dataset[:, :vector_length].min(axis=0)\n",
    "    features_less_min = dataset[:, :vector_length] - dataset[:, :vector_length].min(axis=0)\n",
    "    normed_features = features_less_min / norm_range\n",
    "    return np.concatenate((normed_features, dataset[:, vector_length:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_func = norm_dataset(dataset_array, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667, 0.        ],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667, 0.        ],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667, 0.        ],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667, 0.        ],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667, 0.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_func[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_func == np.concatenate((normed_dataset, dataset_array[:, 4:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataset(dataset, vector_length):\n",
    "    \"\"\"standardizes features in dataset\n",
    "    \"\"\"\n",
    "    features_less_mean = dataset[:, :vector_length] - dataset[:, :vector_length].mean(axis=0)\n",
    "    standardized_features = features_less_mean / dataset[:, :vector_length].std(axis=0)\n",
    "    return np.concatenate((standardized_features, dataset[:, vector_length:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdize_func = standardize_dataset(dataset_array, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673,  0.        ],\n",
       "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673,  0.        ],\n",
       "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673,  0.        ],\n",
       "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673,  0.        ],\n",
       "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673,  0.        ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stdize_func[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 9., 23., 14., 27., 22., 20., 18.,  6.,  5.,  6.]),\n",
       " array([-1.87002413, -1.4338198 , -0.99761547, -0.56141113, -0.1252068 ,\n",
       "         0.31099753,  0.74720187,  1.1834062 ,  1.61961053,  2.05581487,\n",
       "         2.4920192 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_stdize_func[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. run algorithm with scaled features and score new predictions\n",
    "\n",
    "Re-running the naive algorithm with the same process as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_training_set_array = test_func[split_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdized_training_set_array = test_stdize_func[split_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_test_set_array = test_func[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdized_test_set_array = test_stdize_func[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roll-up predictions function\n",
    "def generate_knn_predictions_from_set(test_set, training_set, k, vector_length):\n",
    "    \"\"\"loop over the test set and generate predictions for each feature row\"\"\"\n",
    "    test_set_predictions = []\n",
    "    for row in test_set:\n",
    "        predictions = predict_category_from_knn(row, training_set, k, vector_length)\n",
    "        prediction = predictions[0][0]\n",
    "        test_set_predictions.append(prediction)\n",
    "    return test_set_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_test_predictions = generate_knn_predictions_from_set(\n",
    "    normed_test_set_array,\n",
    "    normed_training_set_array,\n",
    "    4,\n",
    "    4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdized_test_predictions = generate_knn_predictions_from_set(\n",
    "    stdized_test_set_array,\n",
    "    stdized_training_set_array,\n",
    "    4,\n",
    "    4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_prediction_algorithm(test_predictions, test_dataset, category_index):\n",
    "    \"\"\"returns accuracy score from a list of predictions and an array of test data\n",
    "    \"\"\"\n",
    "    accuracy_array = np.equal(\n",
    "        test_predictions, test_dataset[:, category_index]\n",
    "    )\n",
    "    count_accurate_predictions = Counter(accuracy_array)\n",
    "    accuracy_score = float(count_accurate_predictions[True])/len(test_predictions)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_prediction_algorithm(normed_test_predictions, normed_test_set_array, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_prediction_algorithm(stdized_test_predictions, stdized_test_set_array, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funny the feature scaling lead to worse scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
